<html> 
<head> 
<title>Rahul Kidambi</title> 
</head> 
<body bgcolor=#f2f2f2 text=black link=blue vlink=#990000 style='font-family:sans-serif'>


<table width="900" align=center cellspacing="15">
	<tr>
		<td width="20%">
			<IMG src="RK-Mar2017.jpg" width="150">
		</td>
		<td width="70%">
			<div align="left">
			<h1> Rahul Kidambi </h1>
			<p> I am a post-doctoral researcher in the department of Computer Science at Cornell University. <br><br> I earned my PhD studying Machine Learning as a student of <a href="https://homes.cs.washington.edu/~sham/" target="_blank"> Prof. Sham M. Kakade</a> at the University of Washington Seattle.</p>
			<p> &#8226 <a href="CV.pdf" target="_blank">CV</a> &#8226 <a href="https://github.com/rahulkidambi/AccSGD" target="_blank">Github</a> &#8226 <a href="https://scholar.google.com/citations?hl=en&user=vSxL7K8AAAAJ" target="_blank">Scholar</a></p>
			<p> <strong>contact</strong>: rkidambi AT cornell DOT edu </p>
			</div>
		</td>
	</tr>
</table>
<table width="900" align=center cellspacing="20">
	<tr>
		<td width="100%">
		<hr>
			<h2> Research: </h2>
			<p>I am interested in:</p>

			<p> <li> Off-policy (counterfactual) Estimation/Learning for Reinforcement Learning and Contextual Bandits.</li></p>
			<p> <li> Stochastic Approximation for large-scale Machine Learning and Deep Learning.</li></p><br>

			I study applications of these ideas towards recommender systems and user-facing Machine Learning systems.
		</td>
	</tr>

	<tr>
		<td width = "100%">
		<hr>

		<h2> PhD Thesis: </h2>
		<strong>Stochastic Gradient Descent For Modern Machine Learning: Theory, Algorithms And Applications,</strong><br>
		Rahul Kidambi. <br>
		PhD Thesis, University of Washington Seattle, June 2019. <br>
		[<a href="https://digital.lib.washington.edu/researchworks/handle/1773/44183" target="_blank">Link</a>]<br><br>
		<hr>

		<h2> Publications: </h2>
			Asterisk [*] indicates alphabetical ordering of authors.<br><br>

			<h3> Pre-prints: </h3>

			<li> <strong>  MOReL: Model-Based Offline Reinforcement Learning,</strong><br>
				<font color=#ab1f1f>Rahul Kidambi</font>, Aravind Rajeswaran, Praneeth Netrapalli, Thorsten Joachims.<br>
				Manuscript under submission.<br>
				ArXiv manuscript, <a href="https://arxiv.org/abs/2005.05951" target="_blank">abs/2005.05951</a>, May 2020. <br> 
				<br>

			<li> <strong>  Secure Paper Bidding,</strong><br>
				Ruihan Wu, Chuan Guo, Felix Wu, <font color=#ab1f1f>Rahul Kidambi</font>, Laurens van der Maaten, Kilian Q. Weinberger.<br>
				Manuscript under submission.<br>
				<br>

				<h3> Papers: </h3>
			
			<li> <strong>  Leverage Score Sampling for Faster Accelerated Regression and ERM,</strong> [*]<br>
			Naman Agarwal, Sham M. Kakade, <font color=#ab1f1f>Rahul Kidambi</font>, Yin Tat Lee, Praneeth Netrapalli, Aaron Sidford.<br>
			To Appear, <strong> Conference on Algorithmic Learning Theory (ALT)</strong>, 2020.<br>
			ArXiv manuscript, <a href="https://arxiv.org/abs/1711.08426" target="_blank">abs/1711.08426</a>, November 2017. <br> 
			<br>


			<li> <strong>  The Step Decay Schedule: A Near Optimal Geometrically Decaying Learning Rate Procedure For Least Squares,</strong> [*] <sup><a href="#fn3" id="ref3">3</a></sup><br>
			Rong Ge, Sham M. Kakade, <font color=#ab1f1f>Rahul Kidambi</font>, Praneeth Netrapalli.<br>
			In Proc. <strong>Neural Information Processing Systems (NeurIPS)</strong>, 2019.<br>
			ArXiv manuscript, <a href="https://arxiv.org/abs/1904.12838" target="_blank">abs/1904.12838</a>, April 2019.<br> 
			[<a href="http://praneethnetrapalli.org/FinalIterate-StepDecay.pdf" target="_blank">Slides</a>]<br>
			<br>


			<li> <strong> Open Problem: Do Good Algorithms Necessarily Query Bad Points?,</strong> [*]<br>
			Rong Ge, Prateek Jain, Sham M. Kakade, <font color=#ab1f1f>Rahul Kidambi</font>, Dheeraj M. Nagaraj, Praneeth Netrapalli.<br>
			In Proc. <strong>Conference on Learning Theory (COLT)</strong>, 2019.<br> 
			[<a href="http://proceedings.mlr.press/v99/ge19b.html" target="_blank">COLT Proceedings</a>] <br>
			<br>
			
			
			<li> <strong>  On the insufficiency of existing Momentum schemes for Stochastic Optimization,</strong><br>
			<font color=#ab1f1f>Rahul Kidambi</font>, Praneeth Netrapalli, Prateek Jain, Sham M. Kakade.<br>
			In <strong>International Conference on Learning Representations (ICLR)</strong>, 2018. <br><font color="red">Oral Presentation</font>; 23/1002 submissions &asymp; 2% Acceptance Rate.<br>
			Invited paper at the <strong>Information Theory and Applications (ITA)</strong> workshop, San Diego, February 2018.<br>
			ArXiv manuscript, <a href="https://arxiv.org/abs/1803.05591" target="_blank">abs/1803.05591</a>, March 2018.<br>
			[<a href="https://openreview.net/forum?id=rJTutzbA-" target="_blank">Open Review</a>] [<a href="https://ieeexplore.ieee.org/document/8503173" target="_blank">ITA version</a>] [<a href="https://github.com/rahulkidambi/AccSGD" target="_blank">Code</a>] <br>
			<br>
			
			<li> <strong> A Markov Chain Theory Approach to Characterizing the Minimax Optimality of Stochastic Gradient Descent (for Least Squares),</strong> [*]<br>
			Prateek Jain, Sham M. Kakade, <font color=#ab1f1f>Rahul Kidambi</font>, Praneeth Netrapalli, Venkata Krishna Pillutla, Aaron Sidford.<br>
			<i>Invited</i> paper at <strong>FSTTCS 2017</strong>.<br>
			ArXiv manuscript, <a href="https://arxiv.org/abs/1710.09430" target="_blank">abs/1710.09430</a>, October 2017.<br>
			<br>
			
			<li> <strong> Accelerating Stochastic Gradient Descent for least squares regression</strong><sup><a href="#fn2" id="ref2">2</a></sup>, [*]<br>
			Prateek Jain, Sham M. Kakade, <font color=#ab1f1f>Rahul Kidambi</font>, Praneeth Netrapalli, Aaron Sidford.<br>
			In Proc. <strong> Conference on Learning Theory (COLT), 2018</strong>.<br>
			ArXiv manuscript, <a href="https://arxiv.org/abs/1704.08227" target="_blank">abs/1704.08227</a>, April 2017.<br>
			[<a href="http://proceedings.mlr.press/v75/jain18a.html" target="_blank">COLT proceedings</a>] [<a href="https://www.youtube.com/watch?v=_UFGB2MBo4o" target="_blank">Video</a> (Sham at MSR)]<br>
			<br>

			<li> <strong> Parallelizing Stochastic Gradient Descent for Least Squares Regression: mini-batching, averaging, and model misspecification</strong><sup><a href="#fn1" id="ref1">1</a></sup>, [*]<br>
			Prateek Jain, Sham M. Kakade, <font color=#ab1f1f>Rahul Kidambi</font>, Praneeth Netrapalli, Aaron Sidford.<br>
			In<strong> Journal of Machine Learning Research (JMLR)</strong>, Vol. 18 (223), July 2018.<br>
			ArXiv manuscript, <a href="https://arxiv.org/abs/1610.03774" target="_blank">abs/1610.03774</a>, October 2016. Updated, April 2018.<br>
			[<a href="http://jmlr.org/papers/v18/16-595.html" target="_blank">JMLR link</a>]<br>
			<br>

			<li> <strong> Submodular Hamming Metrics</strong>,<br>
			Jennifer Gillenwater, Rishabh K. Iyer, Bethany Lusch, <font color=#ab1f1f>Rahul Kidambi</font>, Jeff A. Bilmes.<br>
			In<strong> Neural Information Processing Systems (NeurIPS)</strong>, December 2015. <font color="red">(Spotlight)</font><br> 
			ArXiv manuscript, <a href="https://arxiv.org/abs/1511.02163" target="_blank">abs/1511.02163</a>, November 2015.<br>
			[<a href="https://papers.nips.cc/paper/5741-submodular-hamming-metrics" target="_blank">NeurIPS proceedings</a>]<br>
			<br>
			
			<li> <strong> On Shannon capacity and causal estimation,</strong><br>
			<font color=#ab1f1f>Rahul Kidambi</font>, Sreeram Kannan.<br>
			<i>Invited</i> paper at <strong>Allerton Conference on Communication, Control, and Computing</strong>, 2015.<br>
			[<a href="https://ieeexplore.ieee.org/document/7447115" target="_blank">Allerton proceedings</a>]<br>
			<br>
			
			<li> <strong> Deformable trellises on factor graphs for robust microtubule tracking in clutter,</strong><br>
			<font color=#ab1f1f>Rahul Kidambi</font>, Min-Chi Shih, Kenneth Rose.<br>
			In <strong>International Symposium on Biomedical Imaging (ISBI)</strong>, May 2012.<br>
			[<a href="https://ieeexplore.ieee.org/document/6235638" target="_blank">ISBI proceedings</a>]<br>
			<br>
			
			<h3> (Selected) Past Work: </h3>
			
			<li> <strong>  A Structured Prediction Approach for Missing Value Imputation,</strong><br>
			<font color=#ab1f1f>Rahul Kidambi</font>, Vinod Nair, Sundararajan Sellamanickam, S. Sathiya Keerthi.<br>
			ArXiv manuscript, <a href="https://arxiv.org/abs/1311.2137" target="_blank">abs/1311.2137</a>, November 2013.<br>
			<br>
			
			<li> <strong>  A Quantitative Evaluation Framework for Missing Value Imputation Algorithms,</strong><br>
			Vinod Nair, <font color=#ab1f1f>Rahul Kidambi</font>, Sundararajan Sellamanickam, S. Sathiya Keerthi, Johannes Gehrke, Vijay Narayanan.<br>
			ArXiv manuscript, <a href="https://arxiv.org/abs/1311.2276" target="_blank">abs/1311.2276</a>, November 2013.<br>
			<br>
			
			
			
			The <a href="http://dblp.uni-trier.de/pers/hd/k/Kidambi:Rahul" target="_blank">dblp</a> maintains a listing of my papers.<br><br><br>

			<sup id="fn1">1. Earlier Version Titled "<strong>Parallelizing Stochastic Approximation Through Mini-Batching and Tail Averaging.</strong>"<a href="#ref1" title="Jump back to footnote 1 in the text.">&#8617</a></sup><br>
			<sup id="fn2">2. Earlier Version Titled "<strong>Accelerating Stochastic Gradient Descent.</strong>"<a href="#ref2" title="Jump back to footnote 2 in the text.">&#8617</a></sup><br>
			<sup id="fn3">3. Earlier Version Titled "<strong>The Step Decay Schedule: A Near Optimal Geometrically Decaying Learning Rate Procedure.</strong>"<a href="#ref3" title="Jump back to footnote 3 in the text.">&#8617</a></sup>
		</td>
	</tr>

<tr>
<td width = "100%">
<hr>
<h2> Academic Service: </h2>
<li type="square"> <strong>Conference Reviewing/Sub-Reviewing</strong>: ISMB 2012, NeurIPS 2016, COLT 2017, COLT 2018, NeurIPS 2018, AISTATS 2019, ICLR 2019, ICML 2019, COLT 2019, ISIT 2019, NeurIPS 2019, ALT 2020, ISIT 2020, COLT 2020, NeurIPS 2020.<br>
<li type="square"> <strong>Journal Refereeing</strong>: Journal of Machine Learning Research (JMLR) - 2015, 2018, 2019, Electronic Journal of Statistics (EJS) - 2017, IEEE Trans. on Information Theory - 2018.<br>
<br>
</td>
</tr>

<tr>
<td width = "100%">
<hr>
<h2> Teaching: </h2>

I have been a Teaching Assistant for the following classes:<br><br>
<li type="square"><a href="https://courses.cs.washington.edu/courses/cse547/18sp/" target="_blank">CSE 547/STAT 548</a>: Machine Learning for Big Data. (Spring 2018).<br>
<li type="square">EE 514a: Information Theory-I (Autumn 2015).<br>
<li type="square">EE 215: Fundamentals of Electrical Engineering (Autumn 2014, Winter 2015).<br>
<br>
</td>
</tr>

<tr>
<td width = "100%">
<hr>
<h2> Miscellaneous: </h2>
&#8226 Football &#8226 Basketball &#8226 Travel &#8226 Music &#8226 Running.
<br>
</td>
</tr>
</body> 

</html> 
