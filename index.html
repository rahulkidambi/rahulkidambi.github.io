<html> 
<head> 
<title>Rahul Kidambi</title> 
</head> 
<body bgcolor=#f2f2f2 text=black link=blue vlink=#990000 style='font-family:sans-serif'>


<table width="700" align=center cellspacing="15">
	<tr>
		<td width="20%">
			<IMG src="RK-Mar2017.jpg" width="175">
		</td>
		<td width="55%">
			<div align="left">
			<h1> Rahul Kidambi </h1>
			<p> I am a graduate student of <a href="https://homes.cs.washington.edu/~sham/" target="_blank"> Prof. Sham M. Kakade</a>  studying Machine Learning at the University of Washington, Seattle. </p>
			<p> &#8226 <a href="CV.pdf" target="_blank">CV</a> &#8226 <a href="https://github.com/rahulkidambi/AccSGD" target="_blank">Github</a> &#8226 <a href="https://scholar.google.com/citations?hl=en&user=vSxL7K8AAAAJ" target="_blank">Scholar</a></p>
			<p> <strong>contact</strong>: rkidambi AT uw DOT edu</p>
			</div>
		</td>
	</tr>
</table>
<table width="825" align=center cellspacing="20">
	<tr>
		<td width="100%">
		<hr>
			<h2> Research: </h2>
			<p> I am interested in the design and implementation of algorithms for Machine Learning and Deep Learning.</p>

			<p> Previously, I spent time at Microsoft Research, India, working on problems at the intersection of Structured Prediction, Semi-Supervised Learning and Active Learning. </p>
		</td>
	</tr>

	<tr>
		<td width = "100%">
		<hr>
			<h2> Publications: </h2>
			Asterisk [*] indicates alphabetical ordering of authors.<br><br>
			
			
			<h3> Pre-Prints: </h3>
			
			<li> <strong>  The Step Decay Schedule: A Near Optimal Geometrically Decaying Learning Rate Procedure,</strong> [*]<br>
			Rong Ge, Sham M. Kakade, <i>Rahul Kidambi</i> and Praneeth Netrapalli.<br>
			In Submission. ArXiv manuscript, <a href="https://arxiv.org/abs/1904.12838" target="_blank">abs/1904.12838</a>, April 2019.<br> Initial Version: Open Review <a href="https://openreview.net/forum?id=HJePy3RcF7" target="_blank">Manuscript</a>, September 2018. <br> 
			<br>
			
			
			<li> <strong>  Leverage Score Sampling for Faster Accelerated Regression and ERM,</strong> [*]<br>
			Naman Agarwal, Sham M. Kakade, <i>Rahul Kidambi</i>, Yin Tat Lee, Praneeth Netrapalli and Aaron Sidford.<br>
			In Submission. ArXiv manuscript, <a href="https://arxiv.org/abs/1711.08426" target="_blank">abs/1711.08426</a>, November 2017. <br> 
			<br>
						

			<h3> Papers (and other published material): </h3>

			<li> <strong> Open Problem: Do Good Algorithms Necessarily Query Bad Points?,</strong> [*]<br>
			Rong Ge, Prateek Jain, Sham M. Kakade, <i>Rahul Kidambi</i>, Dheeraj M. Nagaraj, Praneeth Netrapalli.<br>
			In Open Problem Session, <strong>Conference on Learning Theory (COLT)</strong>, 2019.<br> 
			[<a href="http://proceedings.mlr.press/v99/ge19b.html" target="_blank">COLT Proceedings</a>] [<a href="slides-colt19.pdf" target="_blank">Slides</a> (pdf)] <br>
			<br>
			
			
			<li> <strong>  On the insufficiency of existing Momentum schemes for Stochastic Optimization,</strong><br>
			<i>Rahul Kidambi</i>, Praneeth Netrapalli, Prateek Jain and Sham M. Kakade.<br>
			In <strong>International Conference on Learning Representations (ICLR)</strong>, 2018. <br><font color="red">Oral Presentation; 23/1002 submissions &asymp; 2% Acceptance Rate</font>.<br>
			Invited paper at the <strong>Information Theory and Applications (ITA)</strong> workshop, San Diego, February 2018.<br>
			ArXiv manuscript, <a href="https://arxiv.org/abs/1803.05591" target="_blank">abs/1803.05591</a>, March 2018.<br>
			[<a href="https://openreview.net/forum?id=rJTutzbA-" target="_blank">Open Review</a>] [<a href="https://ieeexplore.ieee.org/document/8503173" target="_blank">ITA version</a>] [<a href="https://github.com/rahulkidambi/AccSGD" target="_blank">Code</a>] [<a href="slides-iclr18.pptx" target="_blank">Slides</a> (pptx)] [<a href="poster-iclr18.pdf" target="_blank">Poster</a> (pdf)] <br>
			<br>
			
			<li> <strong> A Markov Chain Theory Approach to Characterizing the Minimax Optimality of Stochastic Gradient Descent (for Least Squares),</strong> [*]<br>
			Prateek Jain, Sham M. Kakade, <i>Rahul Kidambi</i>, Praneeth Netrapalli, Venkata Krishna Pillutla, Aaron Sidford.<br>
			<i>Invited</i> paper at <strong>FSTTCS 2017</strong>.<br>
			ArXiv manuscript, <a href="https://arxiv.org/abs/1710.09430" target="_blank">abs/1710.09430</a>, October 2017.<br>
			<br>
			
			<li> <strong> Accelerating Stochastic Gradient Descent for least squares regression</strong><sup><a href="#fn2" id="ref2">2</a></sup>, [*]<br>
			Prateek Jain, Sham M. Kakade, <i>Rahul Kidambi</i>, Praneeth Netrapalli and Aaron Sidford.<br>
			In <strong> Conference on Learning Theory (COLT), 2018</strong>.<br>
			ArXiv manuscript, <a href="https://arxiv.org/abs/1704.08227" target="_blank">abs/1704.08227</a>, April 2017.<br>
			[<a href="http://proceedings.mlr.press/v75/jain18a.html" target="_blank">COLT proceedings</a>] [Prateek's <a href="slides-colt18.pptx" target="_blank">Slides</a> (pptx)] [<a href="poster-colt18.pdf" target="_blank">Poster</a> (pdf)] [<a href="https://www.youtube.com/watch?v=_UFGB2MBo4o" target="_blank">Video</a> (Sham at MSR)]<br>
			<br>

			<li> <strong> Parallelizing Stochastic Gradient Descent for Least Squares Regression: mini-batching, averaging, and model misspecification</strong><sup><a href="#fn1" id="ref1">1</a></sup>, [*]<br>
			Prateek Jain, Sham M. Kakade, <i>Rahul Kidambi</i>, Praneeth Netrapalli and Aaron Sidford.<br>
			In<strong> Journal of Machine Learning Research (JMLR)</strong>, Vol. 18 (223), July 2018.<br>
			ArXiv manuscript, <a href="https://arxiv.org/abs/1610.03774" target="_blank">abs/1610.03774</a>, October 2016. Updated, April 2018.<br>
			[<a href="http://jmlr.org/papers/v18/16-595.html" target="_blank">JMLR proceedings</a>]<br>
			<br>

			<li> <strong> Submodular Hamming Metrics</strong>,<br>
			Jennifer Gillenwater, Rishabh K. Iyer, Bethany Lusch, <i>Rahul Kidambi</i>, Jeff A. Bilmes.<br>
			In<strong> Neural Information Processing Systems (NeurIPS)</strong>, December 2015. <font color="red">(Spotlight)</font><br> 
			ArXiv manuscript, <a href="https://arxiv.org/abs/1511.02163" target="_blank">abs/1511.02163</a>, November 2015.<br>
			[<a href="https://papers.nips.cc/paper/5741-submodular-hamming-metrics" target="_blank">NeurIPS proceedings</a>]<br>
			<br>
			
			<li> <strong> On Shannon capacity and causal estimation,</strong><br>
			<i>Rahul Kidambi</i> and Sreeram Kannan.<br>
			<i>Invited</i> paper at <strong>Allerton Conference on Communication, Control, and Computing</strong>, 2015.<br>
			[<a href="https://ieeexplore.ieee.org/document/7447115" target="_blank">Allerton proceedings</a>]<br>
			<br>
			
			<li> <strong> Deformable trellises on factor graphs for robust microtubule tracking in clutter,</strong><br>
			<i>Rahul Kidambi</i>, Min-Chi Shih, Kenneth Rose.<br>
			In <strong>International Symposium on Biomedical Imaging (ISBI)</strong>, May 2012.<br>
			[<a href="https://ieeexplore.ieee.org/document/6235638" target="_blank">ISBI proceedings</a>]<br>
			<br>
			
			<h3> (Selected) Past Work: </h3>
			
			<li> <strong>  A Structured Prediction Approach for Missing Value Imputation,</strong><br>
			<i>Rahul Kidambi</i>, Vinod Nair, Sundararajan Sellamanickam, S. Sathiya Keerthi.<br>
			ArXiv manuscript, <a href="https://arxiv.org/abs/1311.2137" target="_blank">abs/1311.2137</a>, November 2013.<br>
			<br>
			
			<li> <strong>  A Quantitative Evaluation Framework for Missing Value Imputation Algorithms,</strong><br>
			Vinod Nair, <i>Rahul Kidambi</i>, Sundararajan Sellamanickam, S. Sathiya Keerthi, Johannes Gehrke, Vijay Narayanan.<br>
			ArXiv manuscript, <a href="https://arxiv.org/abs/1311.2276" target="_blank">abs/1311.2276</a>, November 2013.<br>
			<br>
			
			
			
			The <a href="http://dblp.uni-trier.de/pers/hd/k/Kidambi:Rahul" target="_blank">dblp</a> maintains a listing of my papers.<br><br><br>

			<sup id="fn1">1. Previously titled "<strong>Parallelizing Stochastic Approximation Through Mini-Batching and Tail Averaging.</strong>"<a href="#ref1" title="Jump back to footnote 1 in the text.">&#8617</a></sup><br>
			<sup id="fn2">2. Previously titled "<strong>Accelerating Stochastic Gradient Descent.</strong>"<a href="#ref2" title="Jump back to footnote 2 in the text.">&#8617</a></sup>
		</td>
	</tr>

<tr>
<td width = "100%">
<hr>
<h2> Academic Service: </h2>
<li type="square"> <strong>Conference Reviewing/Sub-Reviewing</strong>: ISMB 2012, NeurIPS 2016, COLT 2017, COLT 2018, NeurIPS 2018, AISTATS 2019, ICLR 2019, ICML 2019, COLT 2019, ISIT 2019, NeurIPS 2019.<br>
<li type="square"> <strong>Journal Refereeing</strong>: Journal of Machine Learning Research (JMLR) - 2015, 2018, 2019, Electronic Journal of Statistics (EJS) - 2017, IEEE Trans. on Information Theory - 2018.<br>
<br>
</td>
</tr>

<tr>
<td width = "100%">
<hr>
<h2> Teaching: </h2>

I have been a Teaching Assistant for the following classes:<br><br>
<li type="square"> <a href="https://courses.cs.washington.edu/courses/cse547/18sp/" target="_blank">CSE 547/STAT 548</a>: Machine Learning for Big Data. (Spring 2018).<br>
<li type="square">EE 514a: Information Theory-I (Autumn 2015).<br>
<li type="square">EE 215: Fundamentals of Electrical Engineering (Autumn 2014, Winter 2015).<br>
<br>
</td>
</tr>

<tr>
<td width = "100%">
<hr>
<h2> Miscellaneous: </h2>
&#8226 Football &#8226 Basketball &#8226 Travel &#8226 Music &#8226 Running.
<br>
</td>
</tr>
</body> 
</html> 
